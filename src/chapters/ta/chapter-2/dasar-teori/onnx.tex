\subsection{\onnx}
\label{subsec:onnx}

\emph{Open Neural Network Exchange} \onnx{} adalah format standar \emph{open-source} untuk merepresentasikan model \ml{} yang memungkinkan interoperabilitas antara berbagai \emph{framework} \dl. Dikembangkan oleh Facebook dan Microsoft pada tahun 2017, \onnx{} telah berkembang menjadi proyek yang lulus dari Linux Foundation AI dengan dukungan dari perusahaan teknologi besar termasuk IBM, Intel, AMD, ARM, Qualcomm, dan NVIDIA \parencite{onnxgithub2019}.

\onnx{} berfungsi sebagai representasi universal struktur komputasi dari \nn. Komponen arsitektur inti \onnx{} terdiri dari beberapa elemen penting. \emph{Node} merepresentasikan operasi matematika. \emph{Edge} merepresentasikan tensor yang mengalir antar operasi. \emph{Initializer} berfungsi untuk menyimpan bobot model dan konstanta yang diperlukan.

% Konsep teknis utama \onnx{} meliputi representasi menengah (\emph{Intermediate Representation}) yang berfungsi sebagai representasi universal untuk menangkap struktur graf komputasi dari jaringan neural. \onnx{} dibangun menggunakan format serialisasi \emph{Protocol Buffers} (protobuf) Google untuk penyimpanan dan transmisi model yang efisien. Format ini juga mendefinisikan \emph{Operator Set} (Opset) yang merupakan koleksi operator berversi untuk mempertahankan kompatibilitas mundur. Arsitektur \onnx{} merepresentasikan jaringan neural sebagai graf terarah asiklik (DAG) dimana \emph{node} merepresentasikan operasi dan \emph{edge} merepresentasikan aliran data.

% \subsubsection{Interoperabilitas dan Optimasi}

\onnx{} menyediakan interoperabilitas yang memungkinkan konversi model ke berbagai format, seperti \pytorch, \tensorflow, Keras, Scikit-learn, dan \emph{framework} lainnya. Hal ini memungkinkan \emph{deployment} tunggal yang memungkinkan pengembang untuk melakukan pelatihan model pada \emph{framework} apapun dan di-\emph{deploy} menggunakan \onnx Runtime. Format ini bersifat agnostik terhadap \emph{hardware} dan memungkinkan model berjalan di berbagai jenis \emph{hardware} seperti CPU, GPU, dan akselerator khusus seperti TPU.

% Dari aspek optimasi, \onnx{} menyediakan optimasi graf otomatis yang mencakup \emph{constant folding}, \emph{operator fusion}, dan eliminasi \emph{node} redundan. Format ini juga menyediakan optimasi spesifik \emph{hardware} yang memanfaatkan \emph{kernel} khusus untuk platform \emph{hardware} berbeda. Efisiensi memori juga menjadi keunggulan dengan alokasi memori yang dioptimalkan dan manajemen \emph{lifecycle} tensor yang efisien.

% \subsubsection{Aplikasi dalam \ml dan \cv}

% \onnx memiliki aplikasi luas dalam berbagai tugas \ml dan \cv. Dalam klasifikasi gambar, \onnx mendukung model seperti ResNet, EfficientNet, dan MobileNet untuk klasifikasi \emph{real-time}. Untuk deteksi objek, format ini kompatibel dengan model \yolo, SSD, dan \rcnn untuk berbagai aplikasi. Aplikasi lainnya mencakup segmentasi semantik dengan model U-Net dan DeepLab, sistem \ocr dan pemahaman dokumen untuk deteksi dan pengenalan teks, serta pengenalan wajah untuk sistem \emph{real-time} dan biometrik.

% Implementasi industri \onnx mencakup berbagai layanan besar seperti layanan Microsoft yang meliputi pencarian Bing, aplikasi Office, dan Azure Cognitive Services. Dalam industri otomotif, \onnx digunakan dalam sistem mengemudi otonom. Sektor kesehatan memanfaatkan \onnx untuk analisis pencitraan medis dan sistem diagnostik, sementara manufaktur menggunakannya untuk sistem kontrol kualitas dan deteksi cacat \parencite{onnxruntime2020}.
