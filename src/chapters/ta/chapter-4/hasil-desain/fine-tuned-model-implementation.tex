\subsubsection{Karakteristik Model yang Dihasilkan}
\label{subsubsec:karakteristik-model}

Model hasil \emph{fine-tuning} menghasilkan sistem yang secara fundamental berbeda dari model base \donutcord{} dalam hal spesialisasi domain dan format output. Sementara \donutcord{} dirancang untuk ekstraksi informasi dari receipt umum dengan format yang beragam, model hasil \emph{fine-tuning} ini dikhususkan untuk ekstraksi informasi dari bukti pembayaran Indonesia dengan struktur output yang highly structured dan konsisten.

Model menggunakan task identifier \texttt{<s\_payment\_proof>} yang memberikan konteks spesifik bahwa input adalah dokumen bukti pembayaran, memungkinkan model untuk mengaktivasi pathway neural yang tepat untuk domain ini. Output model dirancang dengan format XML-like markup yang memfasilitasi parsing otomatis dan integrasi dengan sistem downstream. Struktur output yang dihasilkan mengikuti hierarki yang jelas dengan pembungkusan setiap field menggunakan special tokens, memastikan extractability yang robust dan konsisten.

Dalam hal behavior expectations, model diharapkan menunjukkan performa superior pada domain pembayaran Indonesia dibandingkan model base, dengan kemampuan khusus dalam mengenali format tanggal Indonesia, mata uang Rupiah, dan nama aplikasi pembayaran lokal. Model juga didesain untuk handling multiple input formats termasuk QRIS receipts, bank transfer confirmations, dan payment app screenshots, dengan robustness terhadap variasi layout dan quality gambar yang umum ditemukan dalam penggunaan mobile.

Arsitektur model mempertahankan Vision Encoder-Decoder dari Donut base dengan Swin Transformer sebagai visual encoder dan BART sebagai text decoder, namun dengan modifikasi signifikan pada vocabulary dan generation configuration. Visual encoder tetap menggunakan pre-trained weights dari CORD-v2 untuk memanfaatkan kemampuan visual understanding yang sudah matang, sementara decoder dimodifikasi dengan expansion vocabulary untuk domain-specific tokens.

Model mengimplementasikan field-specific understanding yang memungkinkan differentiated processing untuk berbagai jenis informasi. Numeric fields seperti \texttt{total\_amount} diproses dengan understanding terhadap format currency Indonesia, temporal fields seperti \texttt{transaction\_time} dengan awareness terhadap format datetime lokal, dan identifier fields dengan robustness terhadap alphanumeric patterns yang beragam.

\subsubsection{Implementasi Proses \emph{Fine-tuning}}
\label{subsubsec:implementasi-proses-fine-tuning}

Proses \emph{fine-tuning} menggunakan pendekatan yang mengoptimalkan stabilitas pelatihan dan kualitas hasil dengan mempertimbangkan karakteristik dataset dan keterbatasan sumber daya komputasi. Setup model dimulai dengan konfigurasi robust untuk expansion vocabulary dan penanganan special tokens yang diperlukan untuk domain pembayaran.

Model setup menggunakan pendekatan systematic untuk memastikan stabilitas proses inisialisasi dan konfigurasi. Model dasar \donutcord{} dimodifikasi dengan ekspansi vocabulary untuk menambahkan 14 token khusus domain yang mencakup pasangan token untuk setiap field target dan task identifier. Proses ekspansi vocabulary memerlukan penyesuaian teknis berupa resize token embeddings pada decoder dan pembaruan konfigurasi model untuk memastikan sinkronisasi ukuran vocabulary di semua komponen.

Dataset implementation menggunakan direct JSONL loading dengan robust preprocessing untuk menangani berbagai kondisi data yang tidak ideal. Strategi loading menghindari preprocessing berlebihan sambil mempertahankan kemampuan untuk menangani format data yang tidak konsisten. Sistem pencarian file gambar menggunakan multiple fallback mechanism untuk mengatasi inkonsistensi penamaan file, termasuk direct path matching, case-insensitive matching, dan pencocokan dengan berbagai ekstensi gambar.

Training configuration menggunakan Seq2SeqTrainer dengan parameter yang dioptimalkan untuk domain pembayaran. Learning rate ditetapkan pada 3e-5 dengan weight decay 0.01, menggunakan mixed precision training dengan FP16 untuk optimisasi resource. Gradient accumulation sebanyak 8 steps digunakan untuk mencapai effective batch size yang optimal dengan batch size 1 per device. Early stopping dengan patience 3 epoch diimplementasikan untuk mencegah overfitting.

Sistem evaluasi menggunakan field-specific accuracy measurement yang memberikan insight mendalam tentang performa model pada setiap aspek ekstraksi informasi. Field-level accuracy dihitung untuk setiap field target secara individual, memungkinkan identifikasi field mana yang paling sulit diekstraksi. Overall accuracy menggunakan exact match accuracy untuk keseluruhan structured output, memberikan gambaran performa model secara holistik.

Data collation strategy memastikan konsistensi input model dengan forcing decoder input menggunakan task start token, proper label masking untuk padding tokens, dan batch consistency handling untuk samples dengan ukuran yang bervariasi. Strategi ini memastikan model menerima input yang konsisten dan dapat menghasilkan output sesuai format yang diharapkan.

\subsubsection{Komponen File Model yang Dihasilkan}
\label{subsubsec:komponen-file-model}

Proses \emph{fine-tuning} menghasilkan kumpulan file model yang komprehensif untuk deployment dan further development. Struktur file model mencakup beberapa komponen utama yang masing-masing memiliki fungsi spesifik dalam ecosystem model.

\begin{enumerate}
\item \textbf{added\_tokens.json}: File konfigurasi yang mendokumentasikan semua special tokens yang ditambahkan selama \emph{fine-tuning}, mencakup mapping token ke ID dan metadata yang diperlukan untuk proper tokenization. File ini essential untuk maintaining consistency antara training dan inference environment.

\item \textbf{config.json}: Konfigurasi utama model yang mencakup arsitektur parameters, vocabulary size yang telah diupdate, generation settings, dan model-specific configurations. File ini berfungsi sebagai blueprint untuk model reconstruction dan memastikan compatibility dengan transformers library.

\item \textbf{generation\_config.json}: Konfigurasi khusus untuk generation process yang mencakup \texttt{decoder\_start\_token\_id}, \texttt{forced\_bos\_token\_id}, \texttt{max\_length}, dan beam search parameters yang dioptimalkan untuk domain pembayaran. Konfigurasi ini critical untuk ensuring consistent generation behavior.

\item \textbf{preprocessor\_config.json}: Konfigurasi untuk image preprocessing yang mencakup resize parameters, normalization values, dan input format specifications yang memastikan consistency antara training dan inference data processing.

\item \textbf{pytorch\_model.bin}: Binary file yang mengandung trained model weights dalam format PyTorch. File ini merupakan core model yang mengandung seluruh learned parameters dari proses \emph{fine-tuning} dan merupakan komponen utama untuk model deployment.

\item \textbf{sentencepiece.bpe.model}: Binary model untuk SentencePiece tokenizer yang handle text tokenization dan detokenization. File ini essential untuk proper text processing dan memastikan consistency dalam vocabulary handling.

\item \textbf{special\_tokens\_map.json}: Mapping file yang mendefinisikan special tokens dan fungsinya dalam model, termasuk \texttt{pad\_token}, \texttt{eos\_token}, dan domain-specific tokens yang ditambahkan untuk payment processing.

\item \textbf{tokenizer.json dan tokenizer\_config.json}: Konfigurasi lengkap untuk tokenizer yang mencakup vocabulary, merging rules, dan tokenization settings. File ini memastikan proper text processing dan compatibility dengan model architecture yang telah dimodifikasi.

\item \textbf{custom\_model.safetensors}: Alternative format untuk model weights yang menyediakan improved security dan loading performance. Format safetensors menjadi standard baru untuk model distribution dengan better memory efficiency dan security guarantees.
\end{enumerate}

Model hasil \emph{fine-tuning} ini dirancang untuk deployment yang seamless dengan infrastructure modern, supporting both PyTorch native format dan safetensors format untuk flexibility dalam deployment scenarios. Konfigurasi comprehensive memastikan model dapat di-load dan digunakan secara konsisten across different environments, dari development hingga production deployment, dengan minimal configuration overhead dan maximum reliability.