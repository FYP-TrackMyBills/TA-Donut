\subsection{Script Fine-tuning}
\label{subsec:script-fine-tuning}

Script \emph{fine-tuning} merupakan implementasi konkret dari strategi pelatihan yang telah dirancang pada \autoref{subsec:perancangan-fine-tuning}. Script ini dikembangkan dengan pendekatan modular yang memungkinkan fleksibilitas dalam konfigurasi pelatihan dan monitoring proses \emph{fine-tuning} secara real-time.

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.8\textwidth]{images/fine-tuning-script-architecture.png}
%     \caption{Arsitektur script fine-tuning dengan komponen utama}
%     \label{fig:fine-tuning-script-architecture}
% \end{figure}

Implementasi script menggunakan framework PyTorch dan Transformers library dari HuggingFace untuk memastikan kompatibilitas dengan model \donut{} dan ekosistem \emph{machine learning} yang luas. Script dirancang dengan beberapa komponen utama: \emph{data loading}, \emph{model initialization}, \emph{training loop}, dan \emph{evaluation pipeline}.

Komponen \emph{data loading} mengimplementasikan \texttt{PaymentProofDataset} class yang secara khusus dirancang untuk menangani format data JSONL dengan struktur yang konsisten. Dataset loader ini memiliki kemampuan untuk memproses gambar dalam berbagai format (JPG, JPEG, PNG) dan melakukan preprocessing yang diperlukan seperti resizing dan normalisasi. Implementasi juga mencakup robust error handling untuk menangani file yang corrupted atau format anotasi yang tidak valid.

Proses inisialisasi model melakukan ekspansi vocabulary untuk mengakomodasi \emph{special tokens} yang spesifik untuk domain pembayaran Indonesia. Script secara otomatis mendeteksi dan menambahkan token baru seperti representasi mata uang rupiah, format tanggal Indonesia, dan terminologi pembayaran lokal. Konfigurasi model disesuaikan dengan kebutuhan pelatihan, termasuk pengaturan \emph{mixed precision} FP16 untuk optimasi memori dan kecepatan pelatihan.

\emph{Training loop} mengimplementasikan strategi yang telah dirancang dengan 30 epoch, \emph{batch size} 1, dan \emph{gradient accumulation} 8 steps. Script mencakup implementasi \emph{early stopping} dengan patience=3 untuk mencegah \emph{overfitting} dan mengoptimalkan penggunaan sumber daya komputasi. Monitoring progres pelatihan dilakukan melalui logging yang comprehensive, mencakup \emph{training loss}, \emph{validation loss}, dan metrik evaluasi khusus.

Script juga mengimplementasikan sistem \emph{checkpoint} otomatis yang menyimpan state model setiap 5 epoch, memungkinkan recovery dari interruption dan analisis evolusi kinerja model. Implementasi mencakup metadata lengkap untuk setiap checkpoint, termasuk konfigurasi pelatihan, metrik performance, dan timestamp untuk audit trail yang lengkap.

Untuk memastikan reproducibility, script mencakup seed management yang konsisten dan logging semua hyperparameter yang digunakan. Dokumentasi inline yang comprehensive memungkinkan maintainability dan adaptasi script untuk eksperimen future. Script dirancang dengan modularitas yang memungkinkan easy integration dengan berbagai \emph{monitoring tools} dan \emph{experiment tracking platforms}.
