\subsection{Perancangan \emph{Fine-Tuning} Model \donut}
\label{subsec:perancangan-fine-tuning-model}

Subbab ini menjelaskan rancangan proses \emph{fine-tuning} model \donut{} untuk tugas ekstraksi data bukti pembayaran. Perancangan ini mencakup pemilihan model dasar, konfigurasi arsitektur, desain format keluaran, strategi \emph{preprocessing} data, dan konfigurasi pelatihan untuk melakukan \emph{fine-tuning} model \donut{} pada \dataset{} yang telah dipersiapkan. Proses ini bertujuan untuk menghasilkan model yang mampu melakukan ekstraksi informasi dari bukti pembayaran dengan akurasi tinggi, serta dapat diintegrasikan ke dalam aplikasi \emph{mobile}.

\subsubsection{Konfigurasi Awal dan Pemilihan Model Dasar}
\label{subsubsec:konfigurasi-awal}

Model dasar yang dipilih untuk proses \emph{fine-tuning} pada \dataset{} bukti pembayaran QRIS dan transfer adalah model \donut{} yang telah di-\emph{fine-tune} pada \dataset{} CORD (\emph{Consolidated Receipt Dataset}) - v2 yang telah disediakan oleh naver-clova-ix. Model tersebut diberi alias \donutcord. Model \donutcord{} dipilih dengan mempertimbangkan faktor-faktor berikut:

\begin{enumerate}
    \item \textbf{\emph{Domain similarity}}: Model \donutcord{} telah dilatih pada \dataset{} dokumen terstruktur yang memiliki kemiripan dengan struk dan bukti pembayaran dalam hal tata letak dan struktur informasi.
    \item \textbf{\emph{Pre-trained capabilities}}: Model ini telah memiliki kemampuan dasar dalam memahami dokumen semi-terstruktur, sehingga dapat mempercepat proses konvergensi selama \emph{fine-tuning}.
    \item \textbf{Arsitektur optimal}: Kombinasi \swin{} sebagai \emph{encoder} visual dan \bart{} sebagai \emph{decoder} teks telah terbukti efektif untuk tugas \emph{Visual Document Understanding}.
\end{enumerate}

Konfigurasi awal dimulai dengan setup lingkungan deterministik menggunakan seed tetap (seed=42) untuk memastikan reproducibility hasil pelatihan. Deteksi perangkat dilakukan secara otomatis dengan prioritas penggunaan GPU untuk mempercepat proses training. Hyperparameter utama ditetapkan dengan batch size 1 per device, maksimum sequence length 512 token, learning rate 3e-5, dan total 40 epochs dengan gradient accumulation steps sebanyak 8 untuk mencapai effective batch size yang optimal.

Ekspansi \emph{vocabulary tokenizer} menjadi langkah krusial dalam konfigurasi awal untuk menambahkan token khusus domain pembayaran. Token domain pembayaran QRIS dan Transfer tersebut berjumlah 14, terdiri dari:
\begin{enumerate}
    \item Token pembuka dan penutup untuk setiap \emph{field} target ekstraksi:
    \begin{enumerate}
        \item \texttt{<s\_total\_amount>}, \texttt{</s\_total\_amount>}
        \item \texttt{<s\_transaction\_time>}, \texttt{</s\_transaction\_time>}
        \item \texttt{<s\_transaction\_identifier>}, \texttt{</s\_transaction\_identifier>}
        \item \texttt{<s\_target\_name>}, \texttt{</s\_target\_name>}
        \item \texttt{<s\_type>}, \texttt{</s\_type>}
        \item \texttt{<s\_application>}, \texttt{</s\_application>}
    \end{enumerate}
    \item Token \emph{task identifier}: \texttt{<s\_payment\_proof>}, \texttt{</s\_payment\_proof>}
\end{enumerate}

Ekspansi \emph{vocabulary} ini memerlukan penyesuaian dimensi \emph{embedding layer} pada \decoder{} dan konfigurasi ulang parameter \texttt{decoder\_start\_token\_id} untuk memastikan model memulai generasi dengan token \emph{task} yang tepat. Konfigurasi model juga diperbarui untuk menyinkronkan ukuran \emph{vocabulary} baru pada semua komponen model, termasuk pengaturan \texttt{forced\_bos\_token\_id} dan \texttt{pad\_token\_id} untuk memastikan konsistensi dalam proses generasi.

\subsubsection{Desain Format Keluaran Terstruktur}
\label{subsubsec:desain-format-keluaran}

Format keluaran model dirancang menggunakan \emph{markup} berbasis XML dengan struktur hierarkis yang memungkinkan ekstraksi informasi yang konsisten dan parsing otomatis. Format yang dirancang mengikuti struktur berikut:

\begin{verbatim}
<s_payment_proof>
<s_total_amount>nilai_total</s_total_amount>
<s_transaction_time>waktu_transaksi</s_transaction_time>
<s_transaction_identifier>id_transaksi</s_transaction_identifier>
<s_type>jenis_transaksi</s_type>
<s_target_name>nama_tujuan</s_target_name>
<s_application>aplikasi_pembayaran</s_application>
</s_payment_proof>
\end{verbatim}

Token \texttt{<s\_payment\_proof>} berfungsi sebagai task prompt yang memberikan konteks kepada model bahwa tugas yang dijalankan adalah ekstraksi informasi dari dokumen bukti pembayaran, membedakannya dari tugas ekstraksi dokumen struk pembayaran pada \donutcord. Setiap field target dibungkus dengan pasangan token pembuka dan penutup yang unik, memungkinkan parsing yang robust dan deteksi field yang kosong atau missing.

Desain format ini mempertimbangkan kemudahan integrasi dengan sistem downstream melalui parsing berbasis regular expression yang dapat mengekstrak setiap field secara individual. Struktur hierarkis juga memungkinkan validasi output yang komprehensif dan deteksi error dalam generasi model.

\subsubsection{Data Preprocessing dan Dataset Management}
\label{subsubsec:data-preprocessing}

Strategi preprocessing data dirancang untuk menangani karakteristik dataset praktis yang sering mengalami inkonsistensi format dan kualitas. Dataset final yang digunakan terdiri dari 257 sampel training, 56 sampel validation, dan 29 sampel test, dengan total 342 sampel yang telah melewati proses kurasi dan validasi kualitas. Ukuran dataset ini dianggap memadai untuk \emph{fine-tuning} model \donut{} karena beberapa faktor:

\begin{enumerate}
    \item \textbf{Transfer Learning Advantage}: Model dasar \donutcord{} telah memiliki pemahaman yang kuat tentang dokumen terstruktur, sehingga proses \emph{fine-tuning} hanya memerlukan adaptasi domain specifik daripada pembelajaran dari nol.
    \item \textbf{Domain Consistency}: Sampel dataset memiliki konsistensi yang tinggi dalam hal struktur dan format dokumen pembayaran, mengurangi kebutuhan akan diversitas yang ekstensif.
    \item \textbf{Quality over Quantity}: Setiap sampel telah melalui proses kurasi manual yang ketat, memastikan kualitas anotasi yang tinggi dan mengurangi noise dalam data training.
    \item \textbf{Targeted Task Scope}: Tugas ekstraksi informasi pembayaran memiliki scope yang terdefinisi dengan baik dengan field target yang terbatas, memungkinkan pembelajaran yang efisien dengan dataset yang lebih kecil.
\end{enumerate}

Implementasi dataset menggunakan class \texttt{PaymentProofDataset} yang menangani loading data dari file metadata berformat JSONL. Sistem pencarian file gambar yang fleksibel diimplementasikan untuk mengatasi inkonsistensi penamaan file melalui multiple fallback mechanisms: direct path matching, case-insensitive matching, pencocokan dengan berbagai ekstensi gambar (.jpg, .jpeg, .png), dan partial matching untuk nama file tanpa ekstensi.

Setiap sampel data melalui validasi untuk memastikan keberadaan file gambar yang valid, kelengkapan ground truth annotation, dan konsistensi format field value. Preprocessing gambar menggunakan processor bawaan dari model \donutcord{} untuk mempertahankan konsistensi dengan pre-training, dengan dukungan augmentation sederhana berupa brightness adjustment untuk meningkatkan robustness model terhadap variasi pencahayaan.

\subsubsection{Konfigurasi Training dan Evaluasi}
\label{subsubsec:konfigurasi-training}

Konfigurasi training menggunakan \texttt{Seq2SeqTrainer} dari library Transformers dengan parameter yang dioptimalkan untuk domain pembayaran. Training arguments mencakup strategi evaluasi dan penyimpanan per epoch, dengan \texttt{predict\_with\_generate=True} untuk memungkinkan evaluasi kualitas generasi selama proses training. Learning rate ditetapkan pada 3e-5 dengan weight decay 0.01 untuk regularisasi model dan pencegahan overfitting.

Mixed precision training dengan FP16 diaktifkan untuk optimisasi penggunaan memori, memungkinkan training pada GPU dengan kapasitas terbatas. Gradient accumulation sebanyak 8 steps digunakan untuk mencapai effective batch size yang lebih besar tanpa overhead memori yang signifikan. Early stopping dengan patience 3 epoch diimplementasikan untuk mencegah overfitting dan mengoptimalkan performa pada validation set.

Sistem evaluasi menggunakan metrik akurasi berbasis field untuk memberikan insight mendalam tentang performa model pada setiap aspek ekstraksi informasi. Akurasi dihitung secara individual untuk setiap field target (\texttt{total\_amount}, \texttt{transaction\_time}, \texttt{transaction\_identifier}, \texttt{type}, \texttt{target\_name}, \texttt{application}) serta akurasi keseluruhan menggunakan exact match untuk structured output lengkap.

Data collation strategy dirancang khusus untuk memastikan konsistensi input model dengan forcing decoder input menggunakan task start token, proper label masking untuk padding tokens (nilai -100 untuk ignore dalam loss calculation), dan batch consistency handling untuk samples dengan ukuran yang bervariasi. Strategi ini memastikan model menerima input yang konsisten dan dapat menghasilkan output yang sesuai dengan format yang diharapkan.